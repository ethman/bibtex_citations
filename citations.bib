@Article{rafii_repeating_2013,
	title = {{REpeating Pattern Extraction Technique (REPET): A Simple Method for Music/Voice Separation}},
	volume = 21,
	issn = {1558-7916, 1558-7924},
	shorttitle = {{REpeating} {Pattern} {Extraction} {Technique} ({REPET})},
	url = {http://ieeexplore.ieee.org/document/6269059/},
	doi = {10.1109/TASL.2012.2213249},
	number = 1,
	urldate = {2018-06-13TZ},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Rafii, Zafar and Pardo, Bryan},
	month = jan,
	year = 2013,
	pages = {73--84}
}
@Article{vandewalle_reproducible_2009,
	title = {{Reproducible Research in Signal Processing}},
	volume = 26,
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/4815541/},
	doi = {10.1109/MSP.2009.932122},
	number = 3,
	urldate = {2018-06-13TZ},
	journal = {IEEE Signal Processing Magazine},
	author = {Vandewalle, Patrick and Kovacevic, Jelena and Vetterli, Martin},
	month = may,
	year = 2009,
	pages = {37--47}
}
@InCollection{tichavsky_2016_2017,
	address = {Cham},
	title = {{The 2016 Signal Separation Evaluation Campaign}},
	volume = 10169,
	isbn = {9783319535463 9783319535470},
	url = {http://link.springer.com/10.1007/978-3-319-53547-0_31},
	urldate = {2018-06-13TZ},
	publisher = {Springer International Publishing},
	author = {Liutkus, Antoine and St{\"o}ter, Fabian-Robert and Rafii, Zafar and Kitamura, Daichi and Rivet, Bertrand and Ito, Nobutaka and Ono, Nobutaka and Fontecave, Julie},
	editor = {Tichavsk{\'y}, Petr and Babaie-Zadeh, Massoud and Michel, Olivier J.J. and Thirion-Moreau, Nad{\`e}ge},
	year = 2017,
	doi = {10.1007/978-3-319-53547-0_31},
	pages = {323--332},
	booktitle = {Latent Variable Analysis and Signal Separation},
	abstract = {n this paper, we report the results of the 2016 community-based Signal Separation Evaluation Campaign (SiSEC 2016). This edition comprises four tasks. Three focus on the separation of speech and music audio recordings, while one concerns biomedical signals. We summarize these tasks and the performance of the submitted systems, as well as provide a small discussion concerning future trends of SiSEC.}
}
@Article{vincent_signal_2012,
	title = {{The SIgnal Separation Evaluation Campaign (2007-2010): Achievements and Remaining Challenges}},
	volume = 92,
	issn = 01651684,
	shorttitle = {The signal separation evaluation campaign (2007-2010)},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168411003604},
	doi = {10.1016/j.sigpro.2011.10.007},
	language = {en},
	number = 8,
	urldate = {2018-06-13TZ},
	journal = {Signal Processing},
	author = {Vincent, Emmanuel and Araki, Shoko and Theis, Fabian and Nolte, Guido and Bofill, Pau and Sawada, Hiroshi and Ozerov, Alexey and Gowreesunker, Vikrham and Lutter, Dominik and Duong, Ngoc Q.K.},
	month = aug,
	year = 2012,
	pages = {1928--1936}
}
@Article{chao-ling_hsu_improvement_2010,
	title = {{On the Improvement of Singing Voice Separation for Monaural Recordings Using the MIR-1K Dataset}},
	volume = 18,
	issn = {1558-7916},
	url = {http://ieeexplore.ieee.org/document/5153305/},
	doi = {10.1109/TASL.2009.2026503},
	number = 2,
	urldate = {2018-06-13TZ},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {{Chao-Ling Hsu} and Jang, J.-S.R.},
	month = feb,
	year = 2010,
	pages = {310--319}
}
@Misc{rafii_musdb18_2017,
	title = {{The Musdb18 Corpus  for Music Separation}},
	url = {https://zenodo.org/record/1117372},
	abstract = {The sigsep musdb18 data set consists of a total of 150 full-track songs of different styles and includes both the stereo mixtures and the original sources, divided between a training subset and a test subset.  Its purpose is to serve as a reference database for the design and the evaluation of source separation algorithms. The objective of such signal processing methods is to estimate one or more sources from a set of mixtures, e.g. for karaoke applications. It has been used as the official dataset in the professionally-produced music recordings task for SiSEC 2018, which is the international campaign for the evaluation of source separation algorithms.  {\textless}em{\textgreater}musdb18{\textless}/em{\textgreater} contains two folders, a folder with a training set: ‚Äútrain‚Äù, composed of 100 songs, and a folder with a test set: ‚Äútest‚Äù, composed of 50 songs. Supervised approaches should be trained on the training set and tested on both sets.  All files from the {\textless}em{\textgreater}musdb18{\textless}/em{\textgreater} dataset are encoded in the Native Instruments stems format (.mp4). It is a multitrack format composed of 5 stereo streams, each one encoded in AAC @256kbps. These signals correspond to:    0 - The mixture,  1 - The drums,  2 - The bass,  3 - The rest of the accompaniment,  4 - The vocals.   For each file, the mixture correspond to the sum of all the signals. All signals are stereophonic and encoded at 44.1kHz.  As the {\textless}em{\textgreater}MUSDB18{\textless}/em{\textgreater} is encoded as STEMS, it relies on ffmpeg to read the multi-stream files. We provide a python wrapper called stempeg that allows to easily parse the dataset and decode the stem tracks on-the-fly.},
	urldate = {2018-06-13TZ},
	publisher = {Zenodo},
	author = {Rafii, Zafar and Liutkus, Antoine and St√∂ter, Fabian-Robert and Mimilakis, Stylianos Ioannis and Bittner, Rachel},
	month = dec,
	year = 2017,
	doi = {10.5281/zenodo.1117372}
}
@Article{durrieu_musically_2011,
	title = {{A Musically Motivated Mid-Level Representation for Pitch Estimation and Musical Audio Source Separation}},
	volume = 5,
	issn = {1932-4553, 1941-0484},
	url = {http://ieeexplore.ieee.org/document/5784290/},
	doi = {10.1109/JSTSP.2011.2158801},
	number = 6,
	urldate = {2018-06-13TZ},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Durrieu, Jean-Louis and David, Bertrand and Richard, Ga{\"e}l},
	month = oct,
	year = 2011,
	pages = {1180--1191}
}
@InProceedings{hershey_deep_2016,
	title = {{Deep Clustering: Discriminative Embeddings for Segmentation and Separation}},
	isbn = 9781479999880,
	shorttitle = {Deep clustering},
	url = {http://ieeexplore.ieee.org/document/7471631/},
	doi = {10.1109/ICASSP.2016.7471631},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Hershey, John R. and Chen, Zhuo and Le Roux, Jonathan and Watanabe, Shinji},
	month = mar,
	year = 2016,
	pages = {31--35},
	booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {optimisation;source separation;contrastive embedding vectors;deep clustering;discriminative embeddings;low-rank pair-wise affinity matrix;segmentation labels;signal quality;single-channel mixtures;source separation;spectrogram;time-frequency region;Indexes;Machine learning;Neural networks;Spectrogram;Speech;Time-frequency analysis;Training;clustering;deep learning;embedding;speech separation}
}
@Article{po-sen_huang_joint_2015,
	title = {Joint {Optimization} of {Masks} and {Deep} {Recurrent} {Neural} {Networks} for {Monaural} {Source} {Separation}},
	volume = 23,
	issn = {2329-9290, 2329-9304},
	url = {http://ieeexplore.ieee.org/document/7194774/},
	doi = {10.1109/TASLP.2015.2468583},
	number = 12,
	urldate = {2018-06-13TZ},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {{Po-Sen Huang} and {Minje Kim} and Hasegawa-Johnson, Mark and Smaragdis, Paris},
	month = dec,
	year = 2015,
	pages = {2136--2147}
}
@InProceedings{huang_deep_2014,
	title = {{Deep Learning for Monaural Speech Separation}},
	isbn = 9781479928934,
	url = {http://ieeexplore.ieee.org/document/6853860/},
	doi = {10.1109/ICASSP.2014.6853860},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Huang, Po-Sen and Kim, Minje and Hasegawa-Johnson, Mark and Smaragdis, Paris},
	month = may,
	year = 2014,
	pages = {1562--1566},
	booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {learning (artificial intelligence);recurrent neural nets;signal reconstruction;source separation;speech processing;NMF models;SARs;SDRs;TIMIT speech corpus;deep learning models;deep neural networks;masking layer;monaural source separation;monaural speech separation;reconstruction constraint;recurrent neural networks;Artificial neural networks;Discrete Fourier transforms;Source separation;Speech;Time-frequency analysis;Training;Deep Learning;Monaural Source Separation;Time-Frequency Masking}
}
@InProceedings{smaragdis_non-negative_2003,
	title = {{Non-Negative Matrix Factorization for Polyphonic Music Transcription}},
	isbn = 9780780378506,
	url = {http://ieeexplore.ieee.org/document/1285860/},
	doi = {10.1109/ASPAA.2003.1285860},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Smaragdis, Paris and Brown, J.C.},
	year = 2003,
	pages = {177--180},
	booktitle = {2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No.03TH8684)},
	keywords = {audio signal processing;matrix decomposition;music;parameter estimation;spectral analysis;audio content modeling;harmonically fixed spectral profile;linear basis transform;nonnegative matrix decomposition;nonnegative matrix factorization;polyphonic music transcription;spectral profile estimation;temporal information estimation;Cost function;Educational institutions;Harmonic analysis;Image analysis;Independent component analysis;Matrix decomposition;Multiple signal classification;Physics;Principal component analysis;Redundancy}
}

@InProceedings{fitzgerald_projet_2016,
	title = {{PROJET - Spatial Audio Separation Using Projections}},
	isbn = 9781479999880,
	url = {http://ieeexplore.ieee.org/document/7471632/},
	doi = {10.1109/ICASSP.2016.7471632},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {FitzGerald, Derry and Liutkus, Antoine and Badeau, Roland},
	month = mar,
	year = 2016,
	pages = {36--40},
	booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {audio signal processing;source separation;inter-channel covariance structures;multichannel audio signals;projection-based method;spatial audio separation;stereophonic music signals;Computational modeling;Multiple signal classification;Source separation;Spatial diversity;Spectrogram;Tensile stress;Time-frequency analysis;ˇ-stable;Sound Source Separation;Spatial Projection}
}

@Article{salamon_melody_2012,
	title = {{Melody Extraction From Polyphonic Music Signals Using Pitch Contour Characteristics}},
	volume = 20,
	issn = {1558-7916, 1558-7924},
	url = {http://ieeexplore.ieee.org/document/6155601/},
	doi = {10.1109/TASL.2012.2188515},
	number = 6,
	urldate = {2018-06-13TZ},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Salamon, Justin and Gomez, Emilia},
	month = aug,
	year = 2012,
	pages = {1759--1770}
}
@Article{rafii_combining_2014,
	title = {{Combining Rhythm-Based and Pitch-Based Methods for Background and Melody Separation}},
	volume = 22,
	issn = {2329-9290, 2329-9304},
	url = {http://ieeexplore.ieee.org/document/6891207/},
	doi = {10.1109/TASLP.2014.2354242},
	number = 12,
	urldate = {2018-06-13TZ},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Rafii, Zafar and Duan, Zhiyao and Pardo, Bryan},
	month = dec,
	year = 2014,
	pages = {1884--1893}
}

@InProceedings{luo_deep_2017,
	title = {{Deep Clustering and Conventional Networks for Music Separation: Stronger Together}},
	isbn = 9781509041176,
	shorttitle = {Deep clustering and conventional networks for music separation},
	url = {http://ieeexplore.ieee.org/document/7952118/},
	doi = {10.1109/ICASSP.2017.7952118},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Luo, Yi and Chen, Zhuo and Hershey, John R. and Le Roux, Jonathan and Mesgarani, Nima},
	month = mar,
	year = 2017,
	pages = {61--65},
	booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {approximation theory;audio signal processing;estimation theory;music;neural nets;pattern clustering;source separation;speaker recognition;audio separation;conventional networks;deep clustering;music separation;signal approximation;source signal estimation;speaker independent speech separation;Instruments;Linear programming;Source separation;Spectrogram;Speech;Time-frequency analysis;Training;Deep clustering;Deep learning;Music separation;Singing voice separation}
}

@InProceedings{huang_singing-voice_2012,
	title = {{Singing-Voice Separation from Monaural Recordings Using Robust Principal Component Analysis}},
	isbn = {9781467300469 9781467300452 9781467300445},
	url = {http://ieeexplore.ieee.org/document/6287816/},
	doi = {10.1109/ICASSP.2012.6287816},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Huang, Po-Sen and Chen, Scott Deeann and Smaragdis, Paris and Hasegawa-Johnson, Mark},
	month = mar,
	year = 2012,
	pages = {57--60},
	booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {audio recording;music;principal component analysis;source separation;speech intelligibility;time-frequency analysis;GNSDR;MIR-1K dataset;binary time-frequency masking method;low-rank subspace;lyric alignment;lyric recognition;monaural recordings;music accompaniment;music information retrieval;repetition structure;robust principal component analysis;singing-voice separation;state-of-the-art approaches;Multiple signal classification;Music;Principal component analysis;Robustness;Sparse matrices;Speech;Time frequency analysis;Music/Voice Separation;Robust Principal Component Analysis;Time-Frequency Masking}
}

@InProceedings{isik_single-channel_2016,
	title = {{Single-Channel Multi-Speaker Separation Using Deep Clustering}},
	url = {http://www.isca-speech.org/archive/Interspeech_2016/abstracts/1176.html},
	doi = {10.21437/Interspeech.2016-1176},
	urldate = {2018-06-13TZ},
	author = {Isik, Yusuf and Roux, Jonathan Le and Chen, Zhuo and Watanabe, Shinji and Hershey, John R.},
	month = sep,
	year = 2016,
	pages = {545--549}
}

@InProceedings{stoter_common_2016,
	title = {{Common Fate Model for Unison Source Separation}},
	isbn = 9781479999880,
	url = {http://ieeexplore.ieee.org/document/7471650/},
	doi = {10.1109/ICASSP.2016.7471650},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Stoter, Fabian-Robert and Liutkus, Antoine and Badeau, Roland and Edler, Bernd and Magron, Paul},
	month = mar,
	year = 2016,
	pages = {126--130},
	booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {amplitude modulation;audio signal processing;discrete Fourier transforms;frequency modulation;musical instruments;signal representation;source separation;2D discrete Fourier transform;amplitude modulation;common fate model;factorization model;frequency modulation;magnitude spectrograms;musical instruments mixtures;signal representation;source separation method;spectral modulation textures;temporal modulation textures;tensor representation;time varying harmonic sources;unison source separation;Frequency modulation;Instruments;Source separation;Spectrogram;Tensile stress;Time-frequency analysis;Common Fate Model;Sound source separation;non-negative tensor factorization}
}

@Article{wolf_rigid_2016,
	title = {{Rigid Motion Model for Audio Source  Separation}},
	volume = 64,
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/7358133/},
	doi = {10.1109/TSP.2015.2508787},
	number = 7,
	urldate = {2018-06-13TZ},
	journal = {IEEE Transactions on Signal Processing},
	author = {Wolf, Guy and Mallat, Stephane and Shamma, Shihab},
	month = apr,
	year = 2016,
	pages = {1822--1831}
}

@InProceedings{pishdadian_multi-resolution_2017,
	title = {{A Multi-resolution Approach to Common Fate-based Audio Separation}},
	isbn = 9781509041176,
	url = {http://ieeexplore.ieee.org/document/7952219/},
	doi = {10.1109/ICASSP.2017.7952219},
	urldate = {2018-06-13TZ},
	publisher = {IEEE},
	author = {Pishdadian, Fatemeh and Pardo, Bryan and Liutkus, Antoine},
	month = mar,
	year = 2017,
	pages = {566--570},
	booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	keywords = {audio signal processing;hearing;modulation;source separation;speech intelligibility;time-frequency analysis;transforms;MCFT;audio sources;auditory model;binary masking;common fate-based audio separation;cortical stage output;harmonic sounds;multiresolution common fate transform;signal representation;spectrotemporal modulation patterns;time-frequency domain;Fourier transforms;Frequency modulation;Source separation;Time-frequency analysis;Two dimensional displays;Audio source separation;Multi-resolution Common Fate Transform}
}

@Article{le_roux_consistent_2013,
	title = {{Consistent Wiener Filtering for Audio Source Separation}},
	volume = 20,
	issn = {1070-9908, 1558-2361},
	url = {http://ieeexplore.ieee.org/document/6334422/},
	doi = {10.1109/LSP.2012.2225617},
	number = 3,
	urldate = {2018-06-13TZ},
	journal = {IEEE Signal Processing Letters},
	author = {Le Roux, Jonathan and Vincent, Emmanuel},
	month = mar,
	year = 2013,
	pages = {217--220}
}

@Book{lee_independent_2011,
	address = {New York; London},
	title = {{Independent Component Analysis: Theory and Applications}},
	isbn = 9781441950567,
	shorttitle = {Independent component analysis},
	language = {English},
	publisher = {Springer},
	author = {Lee, Te-Won},
	year = 2011,
	note = {OCLC: 752483521},
	editor = {Lee, Te-Won},
	keywords = {}
}

@Article{drummond2010warning,
	title = {{Warning: Statistical Benchmarking is Addictive. Kicking the Habit in Machine Learning}},
	volume = 22,
	issn = {0952-813X, 1362-3079},
	shorttitle = {Warning},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09528130903010295},
	doi = {10.1080/09528130903010295},
	language = {en},
	number = 1,
	urldate = {2018-06-13TZ},
	journal = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Drummond, Chris and Japkowicz, Nathalie},
	month = mar,
	year = 2010,
	pages = {67--80}
}

@inproceedings{raffel2014mir_eval,
  author    = {Colin Raffel and
               Brian McFee and
               Eric J. Humphrey and
               Justin Salamon and
               Oriol Nieto and
               Dawen Liang and
               Daniel P. W. Ellis},
  title     = {{MIR{\_}EVAL: A Transparent Implementation of Common MIR Metrics}},
  booktitle = {15th International Society for Music Information
               Retrieval Conference, {ISMIR} 2014, Taipei, Taiwan, October 27-31,
               2014},
  pages     = {367--372},
  year      = {2014},
  crossref  = {DBLP:conf/ismir/2014},
  url       = {http://www.terasoft.com.tw/conf/ismir2014/proceedings/T066_320_Paper.pdf},
  timestamp = {Fri, 19 Dec 2014 14:08:38 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/ismir/RaffelMHSNLE14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bittner2014medleydb,
  author    = {Rachel M. Bittner and
               Justin Salamon and
               Mike Tierney and
               Matthias Mauch and
               Chris Cannam and
               Juan Pablo Bello},
  title     = {{MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research}},
  journal = {15th International Society for Music Information
               Retrieval Conference, {ISMIR} 2014, Taipei, Taiwan, October 27-31,
               2014},
  pages     = {155--160},
  year      = {2014},
  crossref  = {DBLP:conf/ismir/2014},
  url       = {http://www.terasoft.com.tw/conf/ismir2014/proceedings/T028_322_Paper.pdf},
  timestamp = {Fri, 19 Dec 2014 14:08:38 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/ismir/BittnerSTMCB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{huang2014singing,
  author    = {Po{-}Sen Huang and
               Minje Kim and
               Mark Hasegawa{-}Johnson and
               Paris Smaragdis},
  title     = {{Singing-Voice Separation from Monaural Recordings using Deep Recurrent
               Neural Networks}},
  journal = {15th International Society for Music Information
               Retrieval Conference, {ISMIR} 2014, Taipei, Taiwan, October 27-31,
               2014},
  pages     = {477--482},
  year      = {2014},
  crossref  = {DBLP:conf/ismir/2014},
  url       = {http://www.terasoft.com.tw/conf/ismir2014/proceedings/T087_154_Paper.pdf},
  timestamp = {Fri, 19 Dec 2014 14:08:38 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/ismir/HuangKHS14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{rafii2012music,
  author    = {Zafar Rafii and
               Bryan Pardo},
  title     = {{Music/Voice Separation Using the Similarity Matrix}},
  journal = {13th International Society for Music Information
               Retrieval Conference, {ISMIR} 2012, Mosteiro S.Bento Da Vit{\'{o}}ria,
               Porto, Portugal, October 8-12, 2012},
  pages     = {583--588},
  year      = {2012},
  crossref  = {DBLP:conf/ismir/2012},
  url       = {http://ismir2012.ismir.net/event/papers/583-ismir-2012.pdf},
  timestamp = {Thu, 25 Oct 2012 15:38:35 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ismir/RafiiP12},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{seetharaman2016simultaneous,
  author    = {Prem Seetharaman and
               Bryan Pardo},
  title     = {{Simultaneous Separation and Segmentation in Layered Music}},
  journal = {17th International Society for Music Information
               Retrieval Conference, {ISMIR} 2016, New York City, United States,
               August 7-11, 2016},
  pages     = {495--501},
  year      = {2016},
  crossref  = {DBLP:conf/ismir/2016},
  url       = {https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/07/057_Paper.pdf},
  timestamp = {Thu, 08 Sep 2016 13:32:51 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ismir/SeetharamanP16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{chan2015vocal,
author={Tak-Shing Chan and Tzu-Chun Yeh and Zhe-Cheng Fan and Hung-Wei Chen and Li Su and Yi-Hsuan Yang and Roger Jang},
booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={{Vocal Activity Informed Singing Voice Separation with the iKala Dataset}},
year={2015},
volume={},
number={},
pages={718-722},
keywords={principal component analysis;speech processing;MIR-IK dataset;iKala dataset;predefined sparsity pattern;robust principal component analysis;vocal activity informed singing voice separation;Electronic publishing;Harmonic analysis;Information services;Internet;MATLAB;Low-rank and sparse decomposition;informed source separation;singing voice separation},
doi={10.1109/ICASSP.2015.7178063},
ISSN={1520-6149},
month={April},}

@article{isik2016single,
  title={{Single-Channel Multi-Speaker Separation Using Deep Clustering}},
  author={Isik, Yusuf and Roux, Jonathan Le and Chen, Zhuo and Watanabe, Shinji and Hershey, John R},
  journal={arXiv preprint arXiv:1607.02173},
  year={2016}
}

@article{spiertz2009source,
  title={{Source-Filter Based Clustering for Monaural Blind Source Separation}},
  author={Spiertz, Martin and Gnann, Volker},
  journal={Proceedings of the 12th International Conference on Digital Audio Effects},
  year={2009},
  address={}
}

@article{fitzgerald2010harmonic,
  title={{Harmonic/Percussive Separation Using Median Filtering}},
  author={FitzGerald, Derry},
  year={2010},
  journal={Proceedings of the 13th International Conference on Digital Audio Effects},
  address={Graz, Austria}
}

@InProceedings{kim2016bitwise,
  author = {Minje Kim and Paris Smaragdis},
  title = {{Bitwise Neural Networks}},
  booktitle = {International Conference on Machine Learning (ICML) Workshop on Resource-Efficient Machine Learning},
  year = {2015},
  month = {Jul},
  address = {Lille, France}
}

@INPROCEEDINGS{fitzgerald2016projet,
  author={Derry FitzGerald and Antoine Liutkus and Roland Badeau},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={{PROJET --- Spatial Audio Separation Using Projections}},
  year={2016},
  volume={},
  number={},
  pages={36-40},
  keywords={audio signal processing;source separation;inter-channel covariance structures;multichannel audio signals;projection-based method;spatial audio separation;stereophonic music signals;Computational modeling;Multiple signal classification;Source separation;Spatial diversity;Spectrogram;Tensile stress;Time-frequency analysis;α-stable;Sound Source Separation;Spatial Projection},
  doi={10.1109/ICASSP.2016.7471632},
  ISSN={},
  month={March},
}

@incollection{rickard2007duet,
  title={{The DUET blind source separation algorithm}},
  author={Rickard, Scott},
  booktitle={Blind Speech Separation},
  pages={217--241},
  year={2007},
  publisher={Springer}
}

@article{rafii2013repeating,
  author={Zafar Rafii and Bryan Pardo},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  title={{REpeating Pattern Extraction Technique (REPET): A Simple Method for Music/Voice Separation}},
  year={2013},
  volume={21},
  number={1},
  pages={73-84},
  keywords={music;speech processing;time-frequency analysis;REPET;full-track real-world songs;melody extraction improvement;music-voice separation;nonrepeating foreground;pitch detection algorithms;preprocessor;repeating background;repeating pattern extraction technique;time-frequency masking;Adaptation models;Estimation;Hidden Markov models;Music;Spectrogram;Speech;Speech processing;Melody extraction;music structure analysis;music/voice separation;repeating patterns},
  doi={10.1109/TASL.2012.2213249},
  ISSN={1558-7916},
  month={Jan},
}

@INPROCEEDINGS{seetharaman2017music,
  author={Prem Seetharaman and Fatemeh Pishdadian and Bryan Pardo},
  booktitle={2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  title={{Music/Voice Separation Using the 2D Fourier Transform}},
  year={2017},
  volume={},
  number={},
  pages={36-40},
  keywords={Fourier transforms;acoustic signal processing;audio signal processing;blind source separation;music;source separation;speech processing;2D Fourier transform;2DFT;audio scene;audio source separation;music-voice separation;sound sources;unsupervised source separation;voice extraction;Fourier transforms;Image processing;Source separation;Spectrogram;Time-frequency analysis;Two dimensional displays;2DFT;Audio source separation;auditory scene analysis;automatic karaoke;foreground/background separation;image processing;singing voice extraction},
  doi={10.1109/WASPAA.2017.8169990},
  ISSN={},
  month={Oct},
}

@inproceedings{liutkus20172016,
  author    = {Antoine Liutkus and
               Fabian{-}Robert St{\"{o}}ter and
               Zafar Rafii and
               Daichi Kitamura and
               Bertrand Rivet and
               Nobutaka Ito and
               Nobutaka Ono and
               Julie Fontecave},
  title     = {{The 2016 SIgnal Separation Evaluation Campaign}},
  booktitle = {Latent Variable Analysis and Signal Separation - 13th International
               Conference, {LVA/ICA} 2017, Grenoble, France, February 21-23, 2017,
               Proceedings},
  pages     = {323--332},
  year      = {2017},
  crossref  = {DBLP:conf/ica/2017},
  url       = {https://doi.org/10.1007/978-3-319-53547-0_31},
  doi       = {10.1007/978-3-319-53547-0_31},
  timestamp = {Wed, 24 May 2017 08:31:03 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ica/LiutkusSRKRIOF17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


